# An√°lisis de Viabilidad - MVP Local Simplificado

## Resumen Ejecutivo

**Pregunta Clave:** ¬øEs posible implementar este ETL de forma local, m√°s simple y r√°pida?

**Respuesta:** ‚úÖ **S√ç, TOTALMENTE VIABLE** con reducciones significativas:
- **Tiempo:** 25 d√≠as ‚Üí **3-5 d√≠as** (85-90% reducci√≥n)
- **Costo:** $126-186/mes ‚Üí **$0-20/mes** (95% reducci√≥n)
- **Complejidad:** Cloud-native distribuido ‚Üí **Script Python local monol√≠tico**
- **Requisito obligatorio:** ‚úÖ ADK de Google se mantiene

---

## Comparativa: Plan Original vs MVP Local

| Aspecto | Plan Original (Cloud) | MVP Local Simplificado |
|---------|----------------------|------------------------|
| **Tiempo implementaci√≥n** | 25 d√≠as (1 dev senior) | 3-5 d√≠as (1 dev) |
| **Componentes** | 6 servicios distribuidos | 1 script Python |
| **Infraestructura** | GCP (Cloud Run, SQL, etc) | Docker Compose local |
| **Costo mensual** | $126-186 | $0-20 |
| **Complejidad** | Alta (microservicios) | Baja (monolito) |
| **Escalabilidad** | Auto-scaling, cloud-native | Limitada (1 m√°quina) |
| **Producci√≥n ready** | S√≠ | No (prototipo) |
| **L√≠neas c√≥digo** | ~7,400 | ~800-1,200 |

---

## An√°lisis de Componentes

### 1. n8n (Orquestador) ‚Üí ‚ùå **ELIMINAR**

**Original:**
- Servicio complejo de orquestaci√≥n
- Requiere hosting ($5-20/mes)
- Configuraci√≥n visual de workflows
- Gesti√≥n de credenciales
- **Tiempo:** 6 d√≠as (EP-05)

**Alternativa Local:**
- Simple `cron` de sistema operativo
- Script Python con scheduler (`schedule` library)
- Archivo `.env` para credenciales
- **Tiempo:** 30 minutos

**Reducci√≥n:** 6 d√≠as ‚Üí 0.5 horas = **99% m√°s r√°pido**

```python
# Reemplazo de n8n (10 l√≠neas)
import schedule
import time

def run_etl():
    print("Ejecutando ETL...")
    # Llamar funci√≥n principal

schedule.every(5).minutes.do(run_etl)

while True:
    schedule.run_pending()
    time.sleep(1)
```

---

### 2. Microservicio Scraper (Playwright) ‚Üí ‚ö†Ô∏è **SIMPLIFICAR**

**Original:**
- Servicio Cloud Run separado
- Express + TypeScript + Playwright
- Rate limiting, health checks
- **Tiempo:** 3 d√≠as (EP-04)
- **Costo:** $3-15/mes

**Alternativa Local:**
- Librer√≠a Python `requests` o `httpx`
- Fallback a `playwright` solo si es necesario
- Sin servicio separado (funci√≥n en script principal)
- **Tiempo:** 2-3 horas

**Reducci√≥n:** 3 d√≠as ‚Üí 2-3 horas = **95% m√°s r√°pido**

**Evaluaci√≥n de necesidad:**
- ‚úÖ Twitter API: No requiere Playwright (API REST)
- ‚ö†Ô∏è Metro Medell√≠n: Probar primero con `requests`, Playwright solo si bloquea
- ‚úÖ RSS feeds: `feedparser` library (Python)

**Conclusi√≥n:** Playwright probablemente **NO NECESARIO** para MVP.

```python
# Reemplazo simple (20 l√≠neas)
import requests
import feedparser

def scrape_metro():
    response = requests.get("https://www.metrodemedellin.gov.co/feed")
    return feedparser.parse(response.content)

def scrape_twitter():
    headers = {"Authorization": f"Bearer {TWITTER_TOKEN}"}
    response = requests.get(TWITTER_API_URL, headers=headers)
    return response.json()
```

---

### 3. ADK Scorer ‚Üí ‚úÖ **MANTENER (OBLIGATORIO)**

**Original:**
- Microservicio FastAPI en Cloud Run
- Pydantic models, structlog
- **Tiempo:** 5 d√≠as (EP-03)
- **Costo:** $5-20/mes

**Alternativa Local:**
- Funci√≥n Python simple (no API REST)
- Llamada directa a Vertex AI desde script principal
- **Tiempo:** 4-6 horas

**Reducci√≥n:** 5 d√≠as ‚Üí 4-6 horas = **90% m√°s r√°pido**

**Costo:** Mismo (Vertex AI API calls), pero sin hosting de microservicio.

```python
# Reemplazo ADK (40 l√≠neas)
from google.cloud import aiplatform
from vertexai.generative_models import GenerativeModel
import json

def score_news_with_adk(news_item):
    model = GenerativeModel("gemini-1.5-flash")

    prompt = f"""
    Analiza esta noticia de movilidad en Medell√≠n:
    T√≠tulo: {news_item['title']}
    Contenido: {news_item['body']}

    Responde en JSON:
    {{"keep": true/false, "severity": "low|medium|high|critical",
      "tags": ["tag1", "tag2"], "summary": "resumen"}}
    """

    response = model.generate_content(prompt)
    return json.loads(response.text)
```

---

### 4. Base de Datos (Cloud SQL + pgvector) ‚Üí ‚ö†Ô∏è **SIMPLIFICAR DR√ÅSTICAMENTE**

**Original:**
- Cloud SQL Postgres 15
- Extensi√≥n pgvector
- 3 tablas, 12 √≠ndices, 7 vistas, 4 funciones
- B√∫squeda sem√°ntica avanzada
- **Tiempo:** 2 d√≠as (EP-02)
- **Costo:** $7-15/mes

**Alternativa Local (Opci√≥n A - SQLite):**
- SQLite local (sin servidor)
- Sin pgvector (embeddings opcionales)
- 2 tablas simples
- **Tiempo:** 1-2 horas
- **Costo:** $0

**Alternativa Local (Opci√≥n B - Postgres Docker):**
- Docker Compose con Postgres + pgvector
- Mantener b√∫squeda sem√°ntica
- **Tiempo:** 2-3 horas
- **Costo:** $0

**Recomendaci√≥n para MVP:** **Opci√≥n A (SQLite)**
- B√∫squeda sem√°ntica NO es cr√≠tica para MVP
- SQLite m√°s que suficiente para prototipo
- Migraci√≥n a Postgres despu√©s si es necesario

**Reducci√≥n:** 2 d√≠as ‚Üí 1-2 horas = **95% m√°s r√°pido**

```python
# Reemplazo SQLite (30 l√≠neas)
import sqlite3
from datetime import datetime
import hashlib

def init_db():
    conn = sqlite3.connect('etl_movilidad.db')
    conn.execute('''
        CREATE TABLE IF NOT EXISTS news_item (
            id INTEGER PRIMARY KEY,
            source TEXT,
            url TEXT UNIQUE,
            hash_url TEXT UNIQUE,
            title TEXT,
            body TEXT,
            published_at TEXT,
            severity TEXT,
            tags TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    return conn

def insert_news(conn, news):
    hash_url = hashlib.sha256(news['url'].encode()).hexdigest()
    try:
        conn.execute('''
            INSERT INTO news_item (source, url, hash_url, title, body,
                                   published_at, severity, tags)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (news['source'], news['url'], hash_url, news['title'],
              news['body'], news['published_at'], news['severity'],
              ','.join(news['tags'])))
        conn.commit()
        return True
    except sqlite3.IntegrityError:
        return False  # Duplicado
```

---

### 5. Embeddings (OpenAI + pgvector) ‚Üí ‚ùå **ELIMINAR para MVP**

**Original:**
- OpenAI API para embeddings
- Almacenamiento en pgvector
- B√∫squeda sem√°ntica
- **Tiempo:** Incluido en workflows (1 d√≠a)
- **Costo:** $5-15/mes

**Alternativa Local:**
- **Eliminar completamente para MVP**
- No es cr√≠tico para funcionalidad b√°sica
- Agregar despu√©s si es necesario

**Reducci√≥n:** 1 d√≠a ‚Üí 0 horas = **100% eliminado**

**Justificaci√≥n:** B√∫squeda sem√°ntica es feature avanzado, no necesario para validar concepto.

---

### 6. Infraestructura (GCP, Terraform) ‚Üí ‚ùå **ELIMINAR**

**Original:**
- Terraform (IaC)
- Cloud Run, Secret Manager
- IAM, Service Accounts
- **Tiempo:** 3 d√≠as (EP-01)
- **Costo:** Incluido en servicios

**Alternativa Local:**
- Docker Compose (opcional)
- Archivo `.env` para secrets
- **Tiempo:** 1 hora (si se usa Docker)
- **Costo:** $0

**Reducci√≥n:** 3 d√≠as ‚Üí 1 hora = **96% m√°s r√°pido**

```yaml
# docker-compose.yml (opcional, 15 l√≠neas)
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: etl_movilidad
      POSTGRES_USER: etl_app
      POSTGRES_PASSWORD: local_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

---

### 7. Observabilidad ‚Üí ‚ö†Ô∏è **SIMPLIFICAR**

**Original:**
- Cloud Logging
- Vistas SQL complejas
- Dashboards
- **Tiempo:** 2 d√≠as (EP-06)

**Alternativa Local:**
- `logging` library de Python (archivo de texto)
- Consultas SQLite simples
- Print statements para debugging
- **Tiempo:** 30 minutos

**Reducci√≥n:** 2 d√≠as ‚Üí 0.5 horas = **97% m√°s r√°pido**

```python
# Logging simple (5 l√≠neas)
import logging

logging.basicConfig(
    filename='etl.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

logging.info("ETL iniciado")
```

---

### 8. Alertas (Slack/Telegram) ‚Üí ‚úÖ **MANTENER (SIMPLIFICADO)**

**Original:**
- Integraci√≥n en n8n
- Webhooks configurables
- **Tiempo:** Incluido en workflows

**Alternativa Local:**
- Librer√≠a `requests` para webhook Slack
- O librer√≠a `python-telegram-bot`
- **Tiempo:** 1 hora

**Reducci√≥n:** Incluido ‚Üí 1 hora

```python
# Alertas simples (10 l√≠neas)
import requests

def send_slack_alert(message):
    webhook_url = os.getenv('SLACK_WEBHOOK_URL')
    requests.post(webhook_url, json={"text": message})

# Usar solo para severity=high/critical
if scoring['severity'] in ['high', 'critical']:
    send_slack_alert(f"üö® {news['title']}")
```

---

## Arquitectura Simplificada (MVP Local)

### Antes (Cloud-Native)

```
Fuentes ‚Üí n8n ‚Üí [ADK Scorer | Scraper] ‚Üí Cloud SQL ‚Üí Alertas
  ‚Üì        ‚Üì              ‚Üì                    ‚Üì          ‚Üì
Twitter  Cron      Cloud Run            pgvector    Slack/
Metro   Workflows  Microservicios       B√∫squeda    Telegram
Medios  Complex    FastAPI/Express      Sem√°ntica
```

**Componentes:** 6 servicios separados
**Costo:** $126-186/mes
**Tiempo:** 25 d√≠as

---

### Despu√©s (Local Monolito)

```
main.py (1 script Python)
    ‚Üì
    ‚îú‚îÄ Scheduler (schedule library) ‚Üí Ejecuta cada 5 min
    ‚îú‚îÄ Extractors (requests/feedparser) ‚Üí Twitter, Metro, RSS
    ‚îú‚îÄ ADK Scorer (Vertex AI API) ‚Üí Gemini 1.5 Flash
    ‚îú‚îÄ SQLite Database ‚Üí Persistencia local
    ‚îî‚îÄ Alerts (requests) ‚Üí Slack webhook
```

**Componentes:** 1 script Python (~800-1,200 l√≠neas)
**Costo:** $0-5/mes (solo API calls)
**Tiempo:** 3-5 d√≠as

---

## Plan de Implementaci√≥n MVP Local

### D√≠a 1: Setup Base (4-5 horas)

**Ma√±ana (2-3h):**
- [ ] Crear proyecto Python
  ```bash
  mkdir etl-movilidad-local
  cd etl-movilidad-local
  python -m venv venv
  source venv/bin/activate  # Windows: venv\Scripts\activate
  ```
- [ ] Instalar dependencias
  ```bash
  pip install google-cloud-aiplatform requests feedparser schedule python-dotenv
  ```
- [ ] Configurar `.env`
  ```
  GOOGLE_CLOUD_PROJECT=tu-proyecto
  TWITTER_BEARER_TOKEN=tu-token
  SLACK_WEBHOOK_URL=tu-webhook
  ```
- [ ] Inicializar SQLite
  ```python
  # db.py - 50 l√≠neas
  import sqlite3
  # ... schema b√°sico
  ```

**Tarde (2h):**
- [ ] Implementar extractores b√°sicos
  ```python
  # extractors.py - 100 l√≠neas
  def extract_twitter(): ...
  def extract_metro(): ...
  def extract_rss(): ...
  ```
- [ ] Test de extracci√≥n (print results)

**Entregable D√≠a 1:** Extracci√≥n funcional desde 2-3 fuentes

---

### D√≠a 2: ADK Scoring (6-7 horas)

**Ma√±ana (3-4h):**
- [ ] Configurar Vertex AI
  ```bash
  gcloud auth application-default login
  gcloud config set project tu-proyecto
  ```
- [ ] Implementar ADK Scorer
  ```python
  # adk_scorer.py - 80 l√≠neas
  from vertexai.generative_models import GenerativeModel

  def score_news(news_item):
      # Prompt optimizado
      # Llamada a Gemini
      # Parse JSON response
      return scoring_result
  ```
- [ ] Crear prompts efectivos
  - System prompt con contexto Medell√≠n
  - User prompt con estructura JSON

**Tarde (3h):**
- [ ] Test con noticias reales
- [ ] Ajustar prompts seg√∫n resultados
- [ ] Implementar retry logic b√°sico
- [ ] Logging de decisiones

**Entregable D√≠a 2:** ADK clasificando noticias correctamente

---

### D√≠a 3: Pipeline Completo (6-7 horas)

**Ma√±ana (3h):**
- [ ] Implementar normalizaci√≥n
  ```python
  # normalizer.py - 60 l√≠neas
  def normalize_news(raw_news, source):
      # Limpiar HTML
      # Generar hash_url
      # Unificar formato
      return normalized
  ```
- [ ] Implementar deduplicaci√≥n (check hash_url en SQLite)
- [ ] Integrar todo en pipeline
  ```python
  # main.py - 150 l√≠neas
  def run_etl_pipeline():
      # 1. Extract
      # 2. Normalize
      # 3. Deduplicate
      # 4. Score (ADK)
      # 5. Filter (keep=true)
      # 6. Save (SQLite)
      # 7. Alert (if high severity)
  ```

**Tarde (3-4h):**
- [ ] Implementar alertas Slack
  ```python
  # alerts.py - 30 l√≠neas
  def send_alert(news_item):
      message = format_slack_message(news_item)
      requests.post(SLACK_WEBHOOK_URL, json={"text": message})
  ```
- [ ] Test end-to-end manual
- [ ] Fix bugs

**Entregable D√≠a 3:** Pipeline completo funcional

---

### D√≠a 4: Scheduler y Refinamiento (4-5 horas)

**Ma√±ana (2h):**
- [ ] Implementar scheduler
  ```python
  # scheduler.py - 20 l√≠neas
  import schedule

  schedule.every(5).minutes.do(run_etl_pipeline)

  while True:
      schedule.run_pending()
      time.sleep(1)
  ```
- [ ] Configurar logging
  ```python
  # logger.py - 30 l√≠neas
  import logging
  # File + console handlers
  ```

**Tarde (2-3h):**
- [ ] Test de ejecuci√≥n continua (30+ min)
- [ ] Verificar duplicados no se insertan
- [ ] Verificar alertas llegan
- [ ] Ajustar intervalos si es necesario

**Entregable D√≠a 4:** Sistema aut√≥nomo ejecut√°ndose

---

### D√≠a 5: Testing y Documentaci√≥n (3-4 horas)

**Ma√±ana (2h):**
- [ ] Crear tests b√°sicos
  ```python
  # test_etl.py - 100 l√≠neas
  import pytest

  def test_normalize():
      assert normalize_news(...) == expected

  def test_adk_scoring():
      result = score_news(sample_news)
      assert 'keep' in result
      assert result['severity'] in VALID_SEVERITIES
  ```
- [ ] Test casos edge (URLs malformadas, HTML roto, etc.)

**Tarde (1-2h):**
- [ ] Crear README_MVP.md
  ```markdown
  # ETL Movilidad - MVP Local

  ## Setup
  1. Install Python 3.11+
  2. pip install -r requirements.txt
  3. Configure .env
  4. python main.py

  ## Configuraci√≥n
  ...
  ```
- [ ] Documentar variables de entorno
- [ ] Crear requirements.txt
- [ ] Script de setup (`setup.sh`)

**Entregable D√≠a 5:** Sistema testeado y documentado

---

## Comparativa Detallada de Esfuerzo

| Tarea | Plan Original | MVP Local | Reducci√≥n |
|-------|---------------|-----------|-----------|
| Infraestructura GCP | 3 d√≠as | 1 hora | 96% |
| Base de Datos | 2 d√≠as | 1-2 horas | 94% |
| Microservicio ADK | 5 d√≠as | 4-6 horas | 90% |
| Microservicio Scraper | 3 d√≠as | 2-3 horas | 95% |
| Workflows n8n | 6 d√≠as | 30 min | 99% |
| Observabilidad | 2 d√≠as | 30 min | 97% |
| Testing | 4 d√≠as | 2-3 horas | 95% |
| **TOTAL** | **25 d√≠as** | **3-5 d√≠as** | **85-90%** |

---

## An√°lisis de Viabilidad por Requisito

### Requisitos Funcionales

| Requisito | Original | MVP Local | Viable? |
|-----------|----------|-----------|---------|
| Extracci√≥n multi-fuente | ‚úÖ 3+ fuentes | ‚úÖ 2-3 fuentes | ‚úÖ S√≠ |
| Normalizaci√≥n | ‚úÖ Compleja | ‚úÖ B√°sica | ‚úÖ S√≠ |
| Deduplicaci√≥n | ‚úÖ hash_url | ‚úÖ hash_url | ‚úÖ S√≠ |
| **Scoring ADK** | ‚úÖ Gemini | ‚úÖ Gemini | ‚úÖ **S√≠ (obligatorio)** |
| Severidad/Tags | ‚úÖ S√≠ | ‚úÖ S√≠ | ‚úÖ S√≠ |
| Persistencia | ‚úÖ Cloud SQL | ‚úÖ SQLite | ‚úÖ S√≠ |
| B√∫squeda sem√°ntica | ‚úÖ pgvector | ‚ùå No | ‚ö†Ô∏è No cr√≠tico |
| Alertas | ‚úÖ Slack/Telegram | ‚úÖ Slack | ‚úÖ S√≠ |
| Ejecuci√≥n autom√°tica | ‚úÖ n8n cron | ‚úÖ schedule lib | ‚úÖ S√≠ |

**Conclusi√≥n:** Todos los requisitos funcionales cr√≠ticos son viables localmente.

---

### Requisitos No Funcionales

| Requisito | Original | MVP Local | Viable? |
|-----------|----------|-----------|---------|
| Escalabilidad | ‚úÖ Auto-scaling | ‚ùå 1 m√°quina | ‚ö†Ô∏è Limitado |
| Alta disponibilidad | ‚úÖ Cloud-native | ‚ùå Single point | ‚ùå No |
| Latencia | ‚úÖ < 5s | ‚úÖ < 10s | ‚úÖ Aceptable |
| Error rate | ‚úÖ < 2% | ‚ö†Ô∏è < 5% | ‚ö†Ô∏è Aceptable |
| Backups autom√°ticos | ‚úÖ Cloud SQL | ‚ùå Manual | ‚ö†Ô∏è No cr√≠tico MVP |
| Monitoreo 24/7 | ‚úÖ Cloud Monitoring | ‚ùå Logs locales | ‚ö†Ô∏è No cr√≠tico MVP |
| Costo | üí∞ $126-186/mes | üí∞ $0-5/mes | ‚úÖ Mucho mejor |

**Conclusi√≥n:** MVP no cumple requisitos de producci√≥n, pero suficiente para **validar concepto**.

---

## Limitaciones del MVP Local

### ‚ùå Lo que NO tendr√°s:

1. **Escalabilidad**
   - 1 m√°quina = 1 l√≠mite de throughput
   - No auto-scaling si crece la carga
   - **Impacto:** OK para ~100-500 noticias/d√≠a, insuficiente para 10,000+

2. **Alta Disponibilidad**
   - Si tu m√°quina se apaga, ETL se detiene
   - Sin redundancia
   - **Impacto:** OK para prototipo, inaceptable para producci√≥n

3. **B√∫squeda Sem√°ntica**
   - Sin embeddings ni pgvector
   - Solo b√∫squeda por texto (LIKE)
   - **Impacto:** Feature avanzado, no cr√≠tico inicialmente

4. **Observabilidad Profesional**
   - Sin dashboards visuales
   - Logs en archivos de texto
   - Sin alertas sofisticadas
   - **Impacto:** Suficiente para debugging, insuficiente para ops

5. **Disaster Recovery**
   - Backups manuales
   - Sin PITR (Point-in-Time Recovery)
   - **Impacto:** Riesgo de p√©rdida de datos

6. **Compliance y Seguridad**
   - Secrets en `.env` (no rotados)
   - Sin encriptaci√≥n en reposo
   - **Impacto:** Inaceptable para producci√≥n con datos sensibles

### ‚úÖ Lo que S√ç tendr√°s:

1. **Validaci√≥n de Concepto**
   - ¬øFunciona la idea?
   - ¬øADK clasifica bien?
   - ¬øLas fuentes tienen data √∫til?

2. **Prototipo Funcional**
   - Extrae noticias reales
   - Clasifica con ADK
   - Alerta en Slack
   - Almacena en DB

3. **Desarrollo R√°pido**
   - 3-5 d√≠as vs 25 d√≠as
   - Iteraci√≥n r√°pida
   - F√°cil debugging

4. **Costo M√≠nimo**
   - $0-5/mes vs $126-186/mes
   - Solo API calls de Vertex AI

5. **Base para Escalar**
   - C√≥digo Python reutilizable
   - Prompts ADK optimizados
   - Schema SQL f√°cil de migrar

---

## Migraci√≥n Futura: Local ‚Üí Cloud

Si el MVP funciona bien y quieres escalar:

### Migraci√≥n Incremental (2-3 semanas)

**Fase 1: Base de Datos (3 d√≠as)**
- Migrar SQLite ‚Üí Cloud SQL Postgres
- Aplicar migraciones del plan original
- Agregar pgvector

**Fase 2: Containerizaci√≥n (2 d√≠as)**
- Dockerizar script Python
- Desplegar en Cloud Run
- Configurar cron con Cloud Scheduler

**Fase 3: Observabilidad (2 d√≠as)**
- Integrar Cloud Logging
- Crear dashboards
- Configurar alertas

**Fase 4: Microservicios (opcional, 1-2 semanas)**
- Separar ADK Scorer
- Separar Scraper
- Implementar n8n si se necesita

**Ventaja:** Puedes migrar incrementalmente seg√∫n necesidad, sin reescribir todo.

---

## Estructura de Archivos MVP

```
etl-movilidad-local/
‚îÇ
‚îú‚îÄ‚îÄ .env                    # Secrets (no versionar)
‚îú‚îÄ‚îÄ .env.example            # Template de variables
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias Python
‚îú‚îÄ‚îÄ README_MVP.md           # Documentaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ main.py                 # Entry point (150 l√≠neas)
‚îú‚îÄ‚îÄ scheduler.py            # Cron local (20 l√≠neas)
‚îÇ
‚îú‚îÄ‚îÄ extractors.py           # Extracci√≥n multi-fuente (100 l√≠neas)
‚îú‚îÄ‚îÄ normalizer.py           # Limpieza y normalizaci√≥n (60 l√≠neas)
‚îú‚îÄ‚îÄ adk_scorer.py           # Scoring con Gemini (80 l√≠neas)
‚îú‚îÄ‚îÄ db.py                   # SQLite operations (100 l√≠neas)
‚îú‚îÄ‚îÄ alerts.py               # Slack notifications (30 l√≠neas)
‚îú‚îÄ‚îÄ logger.py               # Logging config (30 l√≠neas)
‚îÇ
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ system_prompt.txt   # Prompt ADK (50 l√≠neas)
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_extractors.py
‚îÇ   ‚îú‚îÄ‚îÄ test_adk_scorer.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ etl_movilidad.db    # SQLite database
‚îÇ   ‚îî‚îÄ‚îÄ logs/
‚îÇ       ‚îî‚îÄ‚îÄ etl.log         # Logs de ejecuci√≥n
‚îÇ
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ setup.sh            # Setup inicial
    ‚îî‚îÄ‚îÄ query_db.py         # Consultas √∫tiles
```

**Total:** ~800-1,200 l√≠neas de c√≥digo Python (vs 7,400 del plan original)

---

## Recomendaci√≥n Final

### ¬øCu√°ndo usar MVP Local?

‚úÖ **Usa MVP Local si:**
- Quieres validar la idea r√°pidamente (3-5 d√≠as)
- Presupuesto limitado ($0-5/mes)
- Equipo peque√±o (1-2 devs)
- Prototipo o prueba de concepto
- Aprendiendo ADK/ETL
- Volumen bajo (<500 noticias/d√≠a)

### ¬øCu√°ndo usar Plan Original (Cloud)?

‚úÖ **Usa Plan Original si:**
- Producci√≥n real con usuarios
- Alta disponibilidad requerida (99%+)
- Escalabilidad necesaria (1,000+ noticias/d√≠a)
- Compliance y seguridad cr√≠ticos
- Equipo grande (3+ devs)
- Presupuesto disponible ($150+/mes)
- Largo plazo (6+ meses)

---

## Estrategia Recomendada: H√≠brida

### Semana 1-2: MVP Local
1. Implementar MVP local (3-5 d√≠as)
2. Validar concepto
3. Iterar prompts ADK
4. Verificar calidad de fuentes

### Evaluaci√≥n (D√≠a 6-7)
- ¬øADK clasifica bien? (>70% accuracy)
- ¬øLas fuentes tienen suficientes noticias? (>20/d√≠a)
- ¬øLas alertas son √∫tiles? (no spam)

### Decisi√≥n:
- ‚úÖ **Si funciona bien:** Continuar a Semana 3-4
- ‚ùå **Si no funciona:** Pivotar o cancelar (bajo costo hundido)

### Semana 3-4: Migraci√≥n a Cloud (si aplica)
1. Migrar DB a Cloud SQL
2. Containerizar en Cloud Run
3. Agregar observabilidad
4. Desplegar a producci√≥n

**Beneficio:** Validas r√°pido con bajo riesgo antes de invertir en cloud.

---

## Estimaci√≥n de Costos Real

### MVP Local (Mensual)

| Item | Costo |
|------|-------|
| Vertex AI (Gemini) | $2-5 (estimado 1,000-2,000 requests/mes) |
| M√°quina local | $0 (ya la tienes) |
| Twitter API | $0 (tier gratis) o $100 (Basic) |
| **TOTAL** | **$2-105/mes** |

**Nota:** Twitter API es el costo variable m√°s grande. Alternativas:
- Usar tier gratis (limitado)
- Scraping de Twitter (riesgoso, puede bloquear)
- Omitir Twitter inicialmente (usar solo Metro + medios)

### Comparativa Detallada

| Concepto | Cloud (Original) | Local (MVP) | Ahorro |
|----------|------------------|-------------|--------|
| Infraestructura | $16-51/mes | $0 | 100% |
| Hosting n8n | $5-20/mes | $0 | 100% |
| APIs (Twitter, OpenAI) | $105-115/mes | $2-105/mes | 10-95% |
| **TOTAL** | **$126-186/mes** | **$2-105/mes** | **43-98%** |

---

## Riesgos y Mitigaciones

### Riesgo 1: M√°quina local se apaga
**Probabilidad:** Alta
**Impacto:** Alto (ETL se detiene)
**Mitigaci√≥n:**
- Ejecutar en servidor VPS barato ($5/mes DigitalOcean/Hetzner)
- Script de auto-restart en boot
- Monitoreo con herramienta gratuita (UptimeRobot)

### Riesgo 2: SQLite se corrompe
**Probabilidad:** Media
**Impacto:** Alto (p√©rdida de datos)
**Mitigaci√≥n:**
- Backups diarios autom√°ticos (cron + rsync)
- Guardar en Dropbox/Google Drive
- WAL mode habilitado en SQLite

### Riesgo 3: API rate limits
**Probabilidad:** Media
**Impacto:** Medio (menos noticias)
**Mitigaci√≥n:**
- Respetar l√≠mites (sleep entre requests)
- Implementar backoff exponencial
- Diversificar fuentes

### Riesgo 4: Vertex AI cuota excedida
**Probabilidad:** Baja
**Impacto:** Alto (scoring no funciona)
**Mitigaci√≥n:**
- Monitorear cuota en GCP Console
- Configurar alertas de facturaci√≥n
- Fallback: marcar keep=true si API falla

---

## Conclusi√≥n

### ‚úÖ Viabilidad: ALTA

**Es completamente posible** implementar este ETL de forma local y simplificada manteniendo ADK como √∫nico requisito obligatorio.

**Reducci√≥n lograda:**
- ‚è±Ô∏è **Tiempo:** 25 d√≠as ‚Üí 3-5 d√≠as (80-90% reducci√≥n)
- üí∞ **Costo:** $126-186/mes ‚Üí $2-105/mes (43-98% reducci√≥n)
- üìä **Complejidad:** 6 servicios ‚Üí 1 script (83% reducci√≥n)
- üìù **C√≥digo:** 7,400 l√≠neas ‚Üí 800-1,200 l√≠neas (84% reducci√≥n)

**Lo que se mantiene:**
- ‚úÖ ADK de Google (Gemini 1.5 Flash)
- ‚úÖ Extracci√≥n multi-fuente
- ‚úÖ Clasificaci√≥n inteligente (severity, tags, area)
- ‚úÖ Deduplicaci√≥n
- ‚úÖ Alertas
- ‚úÖ Persistencia

**Lo que se pierde:**
- ‚ùå Escalabilidad cloud-native
- ‚ùå Alta disponibilidad
- ‚ùå B√∫squeda sem√°ntica (pgvector)
- ‚ùå Observabilidad profesional
- ‚ùå Microservicios

**Recomendaci√≥n:**
1. **Implementa MVP local** (3-5 d√≠as)
2. **Valida concepto** (1 semana)
3. **Si funciona bien, migra a cloud** (2-3 semanas)
4. **Si no funciona, pivotas r√°pido** (bajo costo hundido)

**Estrategia ganadora:** Empezar local, escalar cuando sea necesario.

---

**Pr√≥ximos Pasos Inmediatos:**
1. Leer documento completo
2. Decidir: ¬øMVP local o plan original?
3. Si MVP local: Seguir "Plan de Implementaci√≥n MVP Local" (D√≠a 1-5)
4. Si plan original: Seguir `PLAN_IMPLEMENTACION.md`

**Pregunta clave a responder:** ¬øNecesitas validar la idea o lanzar a producci√≥n inmediatamente?
- Validar idea ‚Üí **MVP Local**
- Producci√≥n inmediata ‚Üí **Plan Original Cloud**

---

**Versi√≥n:** 1.0.0
**Fecha:** 2025-01-29
**Estado:** An√°lisis completo - Listo para decisi√≥n
